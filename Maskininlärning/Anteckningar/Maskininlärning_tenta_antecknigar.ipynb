{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anteckningar förberdande för tantan i Maskininlärning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Maskininlärning är tillför att göra förutsägelser och klassifikationer. Vad vi intreserad av mí maskininlärning ar vad vi kan förutsäga med modellen. Inte hur väl den representerar träningsdatan. Det är därför det är så viktigt med testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Används för att träna modellen och testa datan. Genom att testa och träna med hela data setet i omgångar och hittar vilket set som funkar bäst. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calssifaication report\n",
    "\n",
    "**Precisons(a.k.a. Specificity or True Negative Rate)** - Är en procent på vad många sanna neagativa som modellen lyckades förutsäga. Om det viktigt att hitta dom posetiva utfallen är det bäst att optimera med Precisons.\n",
    "\n",
    "**Recall (a.k.a. Sensitivity or True Positive Rate)**  - Är en procent på hur många sanna positiva modellen lyckades förutsäga. Om det viktigt att hitta dom negativa utfallen är det bäst att optimera med Precisons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias - Variance\n",
    "\n",
    "**Bias** - Är hur bra modellen kan hitta det sanna relationen i tränings setet\n",
    "\n",
    "**Variance** - Är hu bra modellen hittar den sanna relationen i test setet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Är en Generalized Linear Model (GLM), likt Linear Reagression.\n",
    "Kan bara bedöm från ett värde mellan 1 och 0. Den funkar ändå att använda varierande data mellan olika värden inte bara binära värden eller classer. Matten som passar linejn till datan är Maximumlilklelihood. Modellen kan också var användbar att hitta vilke features som är relventa till att klassifiera data punkten.  \n",
    "\n",
    "## Coefficients\n",
    "\n",
    "Om vi använde log odds for logistical regression vi kan använda samma teniker som vi använder för linear regression. \n",
    "\n",
    "## MaximumLiklelihood\n",
    "\n",
    "Även om Logistic Regression är väldigt likt Linear Regression så kan man inte använda sum of least squers för att hitta linjen. Detta är för att - och + är oändlig på y-axeln. Avstånden skulle aldrig konvergera. \n",
    "\n",
    "Vad som händer är att vi transformerar log odds till log likelihood återberäknar linjen för log odds om log liklehood är högre än vad den tidigre linjen för log likehood var.  \n",
    "\n",
    "## Mätvärden\n",
    "\n",
    "**$R^2$** - Strävar vi efter ett så nära värde till 1 sm möjligt för en modell som passar data så bra som möjligt. Det finns inte ett sätt att beräkna detta i Logistic Regression.\n",
    "\n",
    "**p-value** - Som tidigare så är värden under 0.05 signifikanta. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "### Ridge Regression, L2\n",
    "\n",
    "I ridges regression så använder vi bias som ett sätt att minmera risken för en overfit och hög variance. Detta i Jämförellse till en Linear Regerssion modell. Detta bias kallas penelty och är ett vädr mellan 0 och posetiv oändligheten. För att hitta det bästa penelty kör en cross validation på modellen. Denna modellen är effektiv när vi har små sett av data på grund av penelty. Kan appliceras på andra modeller för att hitta linjen i data settet. *Penelty ger också möjligheten att lösa för linjen även om data settet inte har fler data punkter än parametrar(Features).* Funkar Bäst när vi vet vad parametrana är och gör. \n",
    "\n",
    "Den optimal lutning för lijen går mot noll ju högre penelty vi sätter, men blir aldrig noll.\n",
    "\n",
    "### Lasso Regression, L1\n",
    "\n",
    "Här också penelty en viktigt del av att passa linjen till data. Fast här så är lutningen vid multiplicering med penelty ett absolut belopp. \n",
    "\n",
    "Om vi ökar penelty så blir tillslut lutning på linjen noll.\n",
    "\n",
    "### Elastic Net Regression\n",
    "\n",
    "Kort så kombinerar Elastic Net panelty för både Lasso och Ridge Regrssion. Denna modellen är kraftfull den kan hitta vilka prarmetrar som är viktiga och vilka som korelaterade. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Principal Component Analysis\n",
    "\n",
    "Den modellen mäter längden från origo till punkten på lijen med utgång från projecerad punkten från datapunkten. Linjen passas till summan av kortatste linjerna från origo. Matten att räkna ut längden är phytogoras sats. PCA är tillför att hitta vilken korelation vi har för olika parametrar och hur dom klustrar sig. Den gjord för att reducera dimensionerna. Används mest i undersökande av data och hitta samband i data.\n",
    "\n",
    "Skalan här i data är mycket viktig. Stand avvikelsen kan användas för att skala dtan till samma skala. Om det är stor skillnad i sklan kan det bli ett väldigt bias för en parameter. \n",
    "\n",
    "Data behöver också vara centrerad. Se till att modeln gör det eller se tilla at göre det manuellt innan. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis - LDA\n",
    "\n",
    "Detta handlar hitta vad som separerar klasserna så mycket som möjligt. Det är likt PCA en teknik att reducer dimnesionerna.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
