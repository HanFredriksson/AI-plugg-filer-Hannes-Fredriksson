{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 19), (66, 19), (134,), (66,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "X, y = data.drop(\"Sales\", axis= 1), data[\"Sales\"]\n",
    "\n",
    "model_ply = PolynomialFeatures(3, include_bias=False)\n",
    "poly_features = model_ply.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train mean: -0.00, std 1.0\n",
      "Scaled X_test mean: -0.12, std 1.12\n"
     ]
    }
   ],
   "source": [
    "# Vi måsta standardiserat våran data innan vi kör en ridge regression\n",
    "# Viktiga är att vi använder samma skalerning på tränings datan som på test datan\n",
    "# Att det kan finnas större eller mindre värden i test datan än tränings datan\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Scaled X_train mean: {scaled_X_train.mean():.2f}, std {scaled_X_train.std():.2}\")\n",
    "print(f\"Scaled X_test mean: {scaled_X_test.mean():.2f}, std {scaled_X_test.std():.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty = 0.\n",
      " MAE  0.3748516441218201\n",
      " MSE  0.26504659505538314\n",
      " RMSE 0.51482676217868\n",
      "\n",
      "Penalty = 10.\n",
      " MAE  0.5392524917636404\n",
      " MSE  0.4487478689277049\n",
      " RMSE 0.51482676217868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ridge_regression(X, penalty=0):\n",
    "    model_ridge = Ridge(alpha=penalty)\n",
    "    model_ridge.fit(scaled_X_train, y_train)\n",
    "    y_pred = model_ridge.predict(X)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred = ridge_regression(scaled_X_test)\n",
    "y_pred_p = ridge_regression(scaled_X_test, penalty=0.5)\n",
    "\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "MSE_p = mean_squared_error(y_test, y_pred_p)\n",
    "RMSE_p = np.sqrt(MSE)\n",
    "MAE_p = mean_absolute_error(y_test, y_pred_p)\n",
    "\n",
    "print (f\"Penalty = 0.\\n MAE  {MAE}\\n MSE  {MSE}\\n RMSE {RMSE}\\n\")\n",
    "print (f\"Penalty = 10.\\n MAE  {MAE_p}\\n MSE  {MSE_p}\\n RMSE {RMSE_p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Här kan vi ses att det inte hjälpte inte att göra ridge regression. Utan så här en vanlig en linjär regression bättre. För att vi vet att Newspaper här inte har något med att förusäga Y på ett bra sätt. I med att vi sprider ut värdena lämnt i en ridge regression över alla beta, så får även variabler som inte har så mycket signifikans stor vikt, för vi jämnar ut det så mycket. Då blir hela regressionen sämre. Lyckades bara öka bias och inte hitta bra balans mellan varianse och bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MAE  8.325426013740572\n",
      " MSE  94.43104457780015\n",
      " RMSE 9.717563716168788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AI-24-programering\\Python-programing-Hannes-Fredriksson\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+01, tolerance: 3.571e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model_lasso = Lasso(alpha=0.2)\n",
    "model_lasso.fit(X_train, y_train)\n",
    "y_pred = model_lasso.predict(scaled_X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print (f\" MAE  {MAE}\\n MSE  {MSE}\\n RMSE {RMSE}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation är mycket dyrt\n",
    "\n",
    "model_ridgeCV = RidgeCV(alphas=[.0001, .001, .01, .1, .5, 1, 5, 10], scoring=\"neg_mean_squared_error\", cv= 5)\n",
    "\n",
    "model_ridgeCV.fit(scaled_X_train, y_train)\n",
    "\n",
    "print(model_ridgeCV.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MAE:   0.46291883026932734\n",
      " MSE:   0.33467924600221605\n",
      " RMSE:  0.5785146895301934\n",
      " Alpha: 0.004968802520343368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lassoCV = LassoCV(eps=0.001, n_alphas=100, max_iter=10000, cv=5)\n",
    "\n",
    "model_lassoCV.fit(scaled_X_train, y_train)\n",
    "\n",
    "y_pred = model_lassoCV.predict(scaled_X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print (f\" MAE:   {MAE}\\n MSE:   {MSE}\\n RMSE:  {RMSE}\\n Alpha: {model_lassoCV.alpha_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MAE  0.46802072322691235\n",
      " MSE  0.3410150044070999\n",
      " RMSE 0.5839648999786716\n",
      " L1 norm: 1.0\n",
      " Alpha: [[4.96880252e+01 4.63392186e+01 4.32161104e+01 4.03034892e+01\n",
      "  3.75871689e+01 3.50539195e+01 3.26914026e+01 3.04881115e+01\n",
      "  2.84333148e+01 2.65170046e+01 2.47298472e+01 2.30631383e+01\n",
      "  2.15087600e+01 2.00591415e+01 1.87072225e+01 1.74464183e+01\n",
      "  1.62705881e+01 1.51740049e+01 1.41513278e+01 1.31975757e+01\n",
      "  1.23081032e+01 1.14785783e+01 1.07049605e+01 9.98348201e+00\n",
      "  9.31062873e+00 8.68312352e+00 8.09791005e+00 7.55213802e+00\n",
      "  7.04314919e+00 6.56846451e+00 6.12577199e+00 5.71291546e+00\n",
      "  5.32788408e+00 4.96880252e+00 4.63392186e+00 4.32161104e+00\n",
      "  4.03034892e+00 3.75871689e+00 3.50539195e+00 3.26914026e+00\n",
      "  3.04881115e+00 2.84333148e+00 2.65170046e+00 2.47298472e+00\n",
      "  2.30631383e+00 2.15087600e+00 2.00591415e+00 1.87072225e+00\n",
      "  1.74464183e+00 1.62705881e+00 1.51740049e+00 1.41513278e+00\n",
      "  1.31975757e+00 1.23081032e+00 1.14785783e+00 1.07049605e+00\n",
      "  9.98348201e-01 9.31062873e-01 8.68312352e-01 8.09791005e-01\n",
      "  7.55213802e-01 7.04314919e-01 6.56846451e-01 6.12577199e-01\n",
      "  5.71291546e-01 5.32788408e-01 4.96880252e-01 4.63392186e-01\n",
      "  4.32161104e-01 4.03034892e-01 3.75871689e-01 3.50539195e-01\n",
      "  3.26914026e-01 3.04881115e-01 2.84333148e-01 2.65170046e-01\n",
      "  2.47298472e-01 2.30631383e-01 2.15087600e-01 2.00591415e-01\n",
      "  1.87072225e-01 1.74464183e-01 1.62705881e-01 1.51740049e-01\n",
      "  1.41513278e-01 1.31975757e-01 1.23081032e-01 1.14785783e-01\n",
      "  1.07049605e-01 9.98348201e-02 9.31062873e-02 8.68312352e-02\n",
      "  8.09791005e-02 7.55213802e-02 7.04314919e-02 6.56846451e-02\n",
      "  6.12577199e-02 5.71291546e-02 5.32788408e-02 4.96880252e-02]\n",
      " [9.93760504e+00 9.26784372e+00 8.64322207e+00 8.06069783e+00\n",
      "  7.51743378e+00 7.01078390e+00 6.53828053e+00 6.09762230e+00\n",
      "  5.68666297e+00 5.30340092e+00 4.94596945e+00 4.61262766e+00\n",
      "  4.30175199e+00 4.01182831e+00 3.74144451e+00 3.48928367e+00\n",
      "  3.25411763e+00 3.03480099e+00 2.83026556e+00 2.63951513e+00\n",
      "  2.46162065e+00 2.29571566e+00 2.14099210e+00 1.99669640e+00\n",
      "  1.86212575e+00 1.73662470e+00 1.61958201e+00 1.51042760e+00\n",
      "  1.40862984e+00 1.31369290e+00 1.22515440e+00 1.14258309e+00\n",
      "  1.06557682e+00 9.93760504e-01 9.26784372e-01 8.64322207e-01\n",
      "  8.06069783e-01 7.51743378e-01 7.01078390e-01 6.53828053e-01\n",
      "  6.09762230e-01 5.68666297e-01 5.30340092e-01 4.94596945e-01\n",
      "  4.61262766e-01 4.30175199e-01 4.01182831e-01 3.74144451e-01\n",
      "  3.48928367e-01 3.25411763e-01 3.03480099e-01 2.83026556e-01\n",
      "  2.63951513e-01 2.46162065e-01 2.29571566e-01 2.14099210e-01\n",
      "  1.99669640e-01 1.86212575e-01 1.73662470e-01 1.61958201e-01\n",
      "  1.51042760e-01 1.40862984e-01 1.31369290e-01 1.22515440e-01\n",
      "  1.14258309e-01 1.06557682e-01 9.93760504e-02 9.26784372e-02\n",
      "  8.64322207e-02 8.06069783e-02 7.51743378e-02 7.01078390e-02\n",
      "  6.53828053e-02 6.09762230e-02 5.68666297e-02 5.30340092e-02\n",
      "  4.94596945e-02 4.61262766e-02 4.30175199e-02 4.01182831e-02\n",
      "  3.74144451e-02 3.48928367e-02 3.25411763e-02 3.03480099e-02\n",
      "  2.83026556e-02 2.63951513e-02 2.46162065e-02 2.29571566e-02\n",
      "  2.14099210e-02 1.99669640e-02 1.86212575e-02 1.73662470e-02\n",
      "  1.61958201e-02 1.51042760e-02 1.40862984e-02 1.31369290e-02\n",
      "  1.22515440e-02 1.14258309e-02 1.06557682e-02 9.93760504e-03]\n",
      " [7.09828931e+00 6.61988837e+00 6.17373005e+00 5.75764131e+00\n",
      "  5.36959556e+00 5.00770279e+00 4.67020038e+00 4.35544450e+00\n",
      "  4.06190212e+00 3.78814351e+00 3.53283532e+00 3.29473404e+00\n",
      "  3.07267999e+00 2.86559165e+00 2.67246036e+00 2.49234548e+00\n",
      "  2.32436973e+00 2.16771499e+00 2.02161826e+00 1.88536795e+00\n",
      "  1.75830046e+00 1.63979690e+00 1.52928007e+00 1.42621172e+00\n",
      "  1.33008982e+00 1.24044622e+00 1.15684429e+00 1.07887686e+00\n",
      "  1.00616417e+00 9.38352073e-01 8.75110284e-01 8.16130780e-01\n",
      "  7.61126296e-01 7.09828931e-01 6.61988837e-01 6.17373005e-01\n",
      "  5.75764131e-01 5.36959556e-01 5.00770279e-01 4.67020038e-01\n",
      "  4.35544450e-01 4.06190212e-01 3.78814351e-01 3.53283532e-01\n",
      "  3.29473404e-01 3.07267999e-01 2.86559165e-01 2.67246036e-01\n",
      "  2.49234548e-01 2.32436973e-01 2.16771499e-01 2.02161826e-01\n",
      "  1.88536795e-01 1.75830046e-01 1.63979690e-01 1.52928007e-01\n",
      "  1.42621172e-01 1.33008982e-01 1.24044622e-01 1.15684429e-01\n",
      "  1.07887686e-01 1.00616417e-01 9.38352073e-02 8.75110284e-02\n",
      "  8.16130780e-02 7.61126296e-02 7.09828931e-02 6.61988837e-02\n",
      "  6.17373005e-02 5.75764131e-02 5.36959556e-02 5.00770279e-02\n",
      "  4.67020038e-02 4.35544450e-02 4.06190212e-02 3.78814351e-02\n",
      "  3.53283532e-02 3.29473404e-02 3.07267999e-02 2.86559165e-02\n",
      "  2.67246036e-02 2.49234548e-02 2.32436973e-02 2.16771499e-02\n",
      "  2.02161826e-02 1.88536795e-02 1.75830046e-02 1.63979690e-02\n",
      "  1.52928007e-02 1.42621172e-02 1.33008982e-02 1.24044622e-02\n",
      "  1.15684429e-02 1.07887686e-02 1.00616417e-02 9.38352073e-03\n",
      "  8.75110284e-03 8.16130780e-03 7.61126296e-03 7.09828931e-03]\n",
      " [5.52089169e+00 5.14880207e+00 4.80179004e+00 4.47816546e+00\n",
      "  4.17635210e+00 3.89487994e+00 3.63237807e+00 3.38756795e+00\n",
      "  3.15925721e+00 2.94633384e+00 2.74776080e+00 2.56257092e+00\n",
      "  2.38986222e+00 2.22879350e+00 2.07858028e+00 1.93849093e+00\n",
      "  1.80784313e+00 1.68600055e+00 1.57236976e+00 1.46639730e+00\n",
      "  1.36756703e+00 1.27539759e+00 1.18944006e+00 1.10927578e+00\n",
      "  1.03451430e+00 9.64791502e-01 8.99767784e-01 8.39126447e-01\n",
      "  7.82572133e-01 7.29829390e-01 6.80641332e-01 6.34768384e-01\n",
      "  5.91987119e-01 5.52089169e-01 5.14880207e-01 4.80179004e-01\n",
      "  4.47816546e-01 4.17635210e-01 3.89487994e-01 3.63237807e-01\n",
      "  3.38756795e-01 3.15925721e-01 2.94633384e-01 2.74776080e-01\n",
      "  2.56257092e-01 2.38986222e-01 2.22879350e-01 2.07858028e-01\n",
      "  1.93849093e-01 1.80784313e-01 1.68600055e-01 1.57236976e-01\n",
      "  1.46639730e-01 1.36756703e-01 1.27539759e-01 1.18944006e-01\n",
      "  1.10927578e-01 1.03451430e-01 9.64791502e-02 8.99767784e-02\n",
      "  8.39126447e-02 7.82572133e-02 7.29829390e-02 6.80641332e-02\n",
      "  6.34768384e-02 5.91987119e-02 5.52089169e-02 5.14880207e-02\n",
      "  4.80179004e-02 4.47816546e-02 4.17635210e-02 3.89487994e-02\n",
      "  3.63237807e-02 3.38756795e-02 3.15925721e-02 2.94633384e-02\n",
      "  2.74776080e-02 2.56257092e-02 2.38986222e-02 2.22879350e-02\n",
      "  2.07858028e-02 1.93849093e-02 1.80784313e-02 1.68600055e-02\n",
      "  1.57236976e-02 1.46639730e-02 1.36756703e-02 1.27539759e-02\n",
      "  1.18944006e-02 1.10927578e-02 1.03451430e-02 9.64791502e-03\n",
      "  8.99767784e-03 8.39126447e-03 7.82572133e-03 7.29829390e-03\n",
      "  6.80641332e-03 6.34768384e-03 5.91987119e-03 5.52089169e-03]\n",
      " [5.23031844e+00 4.87781248e+00 4.54906425e+00 4.24247254e+00\n",
      "  3.95654409e+00 3.68988626e+00 3.44120028e+00 3.20927490e+00\n",
      "  2.99298051e+00 2.79126364e+00 2.60314181e+00 2.42769877e+00\n",
      "  2.26408000e+00 2.11148858e+00 1.96918132e+00 1.83646509e+00\n",
      "  1.71269349e+00 1.59726368e+00 1.48961345e+00 1.38921849e+00\n",
      "  1.29558981e+00 1.20827140e+00 1.12683795e+00 1.05089284e+00\n",
      "  9.80066182e-01 9.14013002e-01 8.52411585e-01 7.94961897e-01\n",
      "  7.41384126e-01 6.91417317e-01 6.44818104e-01 6.01359522e-01\n",
      "  5.60829903e-01 5.23031844e-01 4.87781248e-01 4.54906425e-01\n",
      "  4.24247254e-01 3.95654409e-01 3.68988626e-01 3.44120028e-01\n",
      "  3.20927490e-01 2.99298051e-01 2.79126364e-01 2.60314181e-01\n",
      "  2.42769877e-01 2.26408000e-01 2.11148858e-01 1.96918132e-01\n",
      "  1.83646509e-01 1.71269349e-01 1.59726368e-01 1.48961345e-01\n",
      "  1.38921849e-01 1.29558981e-01 1.20827140e-01 1.12683795e-01\n",
      "  1.05089284e-01 9.80066182e-02 9.14013002e-02 8.52411585e-02\n",
      "  7.94961897e-02 7.41384126e-02 6.91417317e-02 6.44818104e-02\n",
      "  6.01359522e-02 5.60829903e-02 5.23031844e-02 4.87781248e-02\n",
      "  4.54906425e-02 4.24247254e-02 3.95654409e-02 3.68988626e-02\n",
      "  3.44120028e-02 3.20927490e-02 2.99298051e-02 2.79126364e-02\n",
      "  2.60314181e-02 2.42769877e-02 2.26408000e-02 2.11148858e-02\n",
      "  1.96918132e-02 1.83646509e-02 1.71269349e-02 1.59726368e-02\n",
      "  1.48961345e-02 1.38921849e-02 1.29558981e-02 1.20827140e-02\n",
      "  1.12683795e-02 1.05089284e-02 9.80066182e-03 9.14013002e-03\n",
      "  8.52411585e-03 7.94961897e-03 7.41384126e-03 6.91417317e-03\n",
      "  6.44818104e-03 6.01359522e-03 5.60829903e-03 5.23031844e-03]\n",
      " [5.01899244e+00 4.68072915e+00 4.36526367e+00 4.07105951e+00\n",
      "  3.79668373e+00 3.54079995e+00 3.30216188e+00 3.07960722e+00\n",
      "  2.87205200e+00 2.67848531e+00 2.49796437e+00 2.32960993e+00\n",
      "  2.17260202e+00 2.02617591e+00 1.88961844e+00 1.76226448e+00\n",
      "  1.64349375e+00 1.53272777e+00 1.42942705e+00 1.33308845e+00\n",
      "  1.24324275e+00 1.15945235e+00 1.08130914e+00 1.00843253e+00\n",
      "  9.40467549e-01 8.77083184e-01 8.17970713e-01 7.62842224e-01\n",
      "  7.11429211e-01 6.63481264e-01 6.18764847e-01 5.77062167e-01\n",
      "  5.38170109e-01 5.01899244e-01 4.68072915e-01 4.36526367e-01\n",
      "  4.07105951e-01 3.79668373e-01 3.54079995e-01 3.30216188e-01\n",
      "  3.07960722e-01 2.87205200e-01 2.67848531e-01 2.49796437e-01\n",
      "  2.32960993e-01 2.17260202e-01 2.02617591e-01 1.88961844e-01\n",
      "  1.76226448e-01 1.64349375e-01 1.53272777e-01 1.42942705e-01\n",
      "  1.33308845e-01 1.24324275e-01 1.15945235e-01 1.08130914e-01\n",
      "  1.00843253e-01 9.40467549e-02 8.77083184e-02 8.17970713e-02\n",
      "  7.62842224e-02 7.11429211e-02 6.63481264e-02 6.18764847e-02\n",
      "  5.77062167e-02 5.38170109e-02 5.01899244e-02 4.68072915e-02\n",
      "  4.36526367e-02 4.07105951e-02 3.79668373e-02 3.54079995e-02\n",
      "  3.30216188e-02 3.07960722e-02 2.87205200e-02 2.67848531e-02\n",
      "  2.49796437e-02 2.32960993e-02 2.17260202e-02 2.02617591e-02\n",
      "  1.88961844e-02 1.76226448e-02 1.64349375e-02 1.53272777e-02\n",
      "  1.42942705e-02 1.33308845e-02 1.24324275e-02 1.15945235e-02\n",
      "  1.08130914e-02 1.00843253e-02 9.40467549e-03 8.77083184e-03\n",
      "  8.17970713e-03 7.62842224e-03 7.11429211e-03 6.63481264e-03\n",
      "  6.18764847e-03 5.77062167e-03 5.38170109e-03 5.01899244e-03]\n",
      " [4.96880252e+00 4.63392186e+00 4.32161104e+00 4.03034892e+00\n",
      "  3.75871689e+00 3.50539195e+00 3.26914026e+00 3.04881115e+00\n",
      "  2.84333148e+00 2.65170046e+00 2.47298472e+00 2.30631383e+00\n",
      "  2.15087600e+00 2.00591415e+00 1.87072225e+00 1.74464183e+00\n",
      "  1.62705881e+00 1.51740049e+00 1.41513278e+00 1.31975757e+00\n",
      "  1.23081032e+00 1.14785783e+00 1.07049605e+00 9.98348201e-01\n",
      "  9.31062873e-01 8.68312352e-01 8.09791005e-01 7.55213802e-01\n",
      "  7.04314919e-01 6.56846451e-01 6.12577199e-01 5.71291546e-01\n",
      "  5.32788408e-01 4.96880252e-01 4.63392186e-01 4.32161104e-01\n",
      "  4.03034892e-01 3.75871689e-01 3.50539195e-01 3.26914026e-01\n",
      "  3.04881115e-01 2.84333148e-01 2.65170046e-01 2.47298472e-01\n",
      "  2.30631383e-01 2.15087600e-01 2.00591415e-01 1.87072225e-01\n",
      "  1.74464183e-01 1.62705881e-01 1.51740049e-01 1.41513278e-01\n",
      "  1.31975757e-01 1.23081032e-01 1.14785783e-01 1.07049605e-01\n",
      "  9.98348201e-02 9.31062873e-02 8.68312352e-02 8.09791005e-02\n",
      "  7.55213802e-02 7.04314919e-02 6.56846451e-02 6.12577199e-02\n",
      "  5.71291546e-02 5.32788408e-02 4.96880252e-02 4.63392186e-02\n",
      "  4.32161104e-02 4.03034892e-02 3.75871689e-02 3.50539195e-02\n",
      "  3.26914026e-02 3.04881115e-02 2.84333148e-02 2.65170046e-02\n",
      "  2.47298472e-02 2.30631383e-02 2.15087600e-02 2.00591415e-02\n",
      "  1.87072225e-02 1.74464183e-02 1.62705881e-02 1.51740049e-02\n",
      "  1.41513278e-02 1.31975757e-02 1.23081032e-02 1.14785783e-02\n",
      "  1.07049605e-02 9.98348201e-03 9.31062873e-03 8.68312352e-03\n",
      "  8.09791005e-03 7.55213802e-03 7.04314919e-03 6.56846451e-03\n",
      "  6.12577199e-03 5.71291546e-03 5.32788408e-03 4.96880252e-03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AI-24-programering\\Python-programing-Hannes-Fredriksson\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.548e-01, tolerance: 3.571e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model_elstic = ElasticNetCV(l1_ratio=[.1, .5, .7, .9 , .95, .99, 1], eps=0.001, n_alphas=100, max_iter=1000)\n",
    "model_elstic.fit(scaled_X_train, y_train)\n",
    "y_pred = model_elstic.predict(scaled_X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print (f\" MAE  {MAE}\\n MSE  {MSE}\\n RMSE {RMSE}\\n L1 norm: {model_elstic.l1_ratio_}\\n Alpha: {model_elstic.alphas_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
