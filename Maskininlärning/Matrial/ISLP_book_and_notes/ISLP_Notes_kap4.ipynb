{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "When the respons variable is qualitative we need an approache to classify the respons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "This model finds the probalility of the respons Y belongs to a particular category. The model gives an value between 0 and 1. To do this we use logistic function.\n",
    "\n",
    "$p(X) = \\frac{e^{\\beta_0 + \\beta_1X}}{1+ e^{\\beta_0+\\beta_1X}}$\n",
    "\n",
    "How we fit this model is with an method called *maximum likelihood*. The math for this is called *likelihood function* \n",
    "\n",
    "$L(\\beta_0, \\beta_1) = \\prod_{i:y_i=1} p(x) \\prod_{i':y_i'=0} (1-p(x_{i'})) $\n",
    "\n",
    "The z-statistic plays the same role as the t-statistic in the linear regression output. So a large (absolute) value of the z-statistic indicates evidence against the null hypothesis $H_0 : \\beta_1 = 0$.\n",
    "The result we get from a fitted model is a percentage that our question is true. For example if we want to see if somebody will default on there loan, and we run data set from a bank. We can answer that in percentage.\n",
    "\n",
    "## Multipal Logistic regression\n",
    "\n",
    "It as simple as just adding in an other variabel to fromula and calculate the probality of that. Important to note is that in many cases there is an relarion between variabels. There is useful to dig into what that realtonship tells and what the data an tell us. \n",
    "\n",
    "## Multinomial Logistic Regression\n",
    "\n",
    "If we want to extend beyond two calsses in logistic regression, called multinomial logistic regression. Then using the formula: \n",
    "\n",
    "$Pr(Y = k|X=x) = \\frac{e^{\\beta_{k0}+{\\beta_{k1x_1}}+...+{\\beta{kp}{x_p}}}}{1+\\sum^{K-1}_{l=1}e^{\\beta_{l0}+\\beta_{l1x_1}}+...+{\\beta{kp}{x_p}}}$\n",
    "\n",
    "To make use of this we need to make an baseline class to make our probality assumptions. Take note of the choice o basaline greatly influnce the result. This is given by the formula:\n",
    "\n",
    "$log(\\frac{Pr(Y=k)|X=x}{Pr(Y=K)|X=x}) = \\beta_{k0}+\\beta_{k1x_1}+..+\\beta_{kpx_p}$\n",
    "\n",
    "To be mentioned is there is away to treat the class symmetrically. This is called *softmax*. What this dose is estimate coefficients for all K classes. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Models for Classification\n",
    "\n",
    "This is an less direct approach to estimating the probabilties for the classes. In this approach we model the distrubution of X seprately for each response class Y. This is as simpler method to apply when there more then two respons classes. It also out preforms logistic regression when coming to smaller data sets and substantial sepration between the classes.\n",
    "\n",
    "## LDA - Linear Discriminant Analysis\n",
    "\n",
    "LDA is an supervised learning methd for multi-class classification. It models the distribution sepret from each calss. For this to work we need to make some assumptions about our data set. \n",
    "\n",
    "- It has to have an normal distribution (Gassian Distribution)\n",
    "\n",
    "- Equal ovariance matrix for the diffrent classes. \n",
    "\n",
    "- Linear Separability, a linear decision boundary should be sufficient to seperate the clases. \n",
    "\n",
    "The primary ways it seperates the classes in the dataset is through *dimensionnality reduction* and *linear classification* \n",
    "\n",
    "It usefulness is to reduce dimensionality when pre-processing datasets. \n",
    "\n",
    "Fails when calss means are shared and sentive to outliers. \n",
    "\n",
    "## Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "Benfit of QDA comperd to LDA is that it can handel calsses with seperate covariance matrix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
